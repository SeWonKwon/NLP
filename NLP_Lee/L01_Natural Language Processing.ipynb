{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLv9iQK0HOlX"
   },
   "source": [
    "# 자연어 처리(Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inehXda7HZhF"
   },
   "source": [
    "* 자연어는 일상 생활에서 사용하는 언어\n",
    "* 자연어 처리는 자연어의 의미를 분석 처리하는 일\n",
    "* 텍스트 분류, 감성 분석, 문서 요약, 번역, 질의 응답, 음성 인식, 챗봇과 같은 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W53tu5dXuZR_"
   },
   "source": [
    "## 텍스트 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T22:55:54.632386Z",
     "start_time": "2021-09-08T22:55:54.626380Z"
    },
    "id": "7gXKJ2H15wF_"
   },
   "outputs": [],
   "source": [
    "s = 'No pain no gain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T22:56:01.911251Z",
     "start_time": "2021-09-08T22:56:01.892234Z"
    },
    "id": "eDpKqMwU6G6M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'pain' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T22:56:05.682057Z",
     "start_time": "2021-09-08T22:56:05.675049Z"
    },
    "id": "1kXoIXAD6a7J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No', 'pain', 'no', 'gain']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T22:56:15.509272Z",
     "start_time": "2021-09-08T22:56:15.504022Z"
    },
    "id": "71btJnM_6Jp5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split().index('gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:18:28.075844Z",
     "start_time": "2021-09-09T00:18:28.068838Z"
    },
    "id": "IRcGQS4h6nnH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gain'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:18:36.399320Z",
     "start_time": "2021-09-09T00:18:36.385798Z"
    },
    "id": "igK5VIBI6PMo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pain'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:18:48.267971Z",
     "start_time": "2021-09-09T00:18:48.257962Z"
    },
    "id": "bjIMwR776SIv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()[2][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:19:39.730108Z",
     "start_time": "2021-09-09T00:19:39.720002Z"
    },
    "id": "lqk6iozeks2f"
   },
   "outputs": [],
   "source": [
    "s = '한글도 처리 가능'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:19:47.680850Z",
     "start_time": "2021-09-09T00:19:47.671779Z"
    },
    "id": "KLusoOBWkvhI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'처리' in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:19:52.771853Z",
     "start_time": "2021-09-09T00:19:52.765848Z"
    },
    "id": "dy75iFEMkycR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한글도', '처리', '가능']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:20:00.641787Z",
     "start_time": "2021-09-09T00:20:00.625774Z"
    },
    "id": "JrAyEDZdk1Jf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'처리'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.split()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--ANCtg2uPwW"
   },
   "source": [
    "## 영어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxPYRMKXuiAM"
   },
   "source": [
    "#### 대소문자 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkwMuEpRvFI3"
   },
   "source": [
    "* 대소문자를 통합하지 않는다면 컴퓨터는 같은 단어를 다르게 받아들임\n",
    "* 파이썬의 내장 함수 `lower()`, `upper()`를 통해 간단하게 통합 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:21:38.217722Z",
     "start_time": "2021-09-09T00:21:38.202706Z"
    },
    "id": "q9oloj0ivF34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghi ABCDEFGHI\n"
     ]
    }
   ],
   "source": [
    "s = 'AbcDefGhi'\n",
    "str_lower = s.lower()\n",
    "str_upper = s.upper()\n",
    "\n",
    "print(str_lower, str_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwDDC4HjPaWn"
   },
   "source": [
    "### 정규화(Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:22:32.673827Z",
     "start_time": "2021-09-09T00:22:32.663811Z"
    },
    "id": "yRo-_ohoPdAz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I visted UK from US on 22-09-20'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'I visted UK from US on 22-09-20'\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:23:54.454622Z",
     "start_time": "2021-09-09T00:23:54.449619Z"
    },
    "id": "4nP3cRP_Pp09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I visted United Kingdom from United States on 22-09-2020'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_s = s.replace('UK','United Kingdom').replace('US', 'United States')\n",
    "new_s = new_s.replace('-20', '-2020')\n",
    "new_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwfz36YS1FCU"
   },
   "source": [
    "### 정규표현식<sub>Regular Expression</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myBZJRSL1JLE"
   },
   "source": [
    "* 정규 표현식은 특정 문자들을 편리하게 지정하고 추가, 삭제 가능\n",
    "* 데이터 전처리에서 정규 표현식을 많이 사용\n",
    "* 파이썬에서는 정규 표현식을 지원하는 `re` 패키지 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLT-dbGQ1NSe"
   },
   "source": [
    "* 정규 표현식 문법\n",
    "  \n",
    "| 특수문자 | 설명 |\n",
    "| - | - |\n",
    "| `.` | 앞의 문자 1개를 표현 |\n",
    "| `?` | 문자 한개를 표현하나 존재할 수도, 존재하지 않을 수도 있음(0개 또는 1개) |\n",
    "| `*` | 앞의 문자가 0개 이상 |\n",
    "| `+` | 앞의 문자가 최소 1개 이상 |\n",
    "| `^` | 뒤의 문자로 문자열이 시작 |\n",
    "| `\\$` | 앞의 문자로 문자열이 끝남 |\n",
    "| `\\{n\\}` | `n`번만큼 반복 |\n",
    "| `\\{n1, n2\\}` | `n1` 이상, `n2` 이하만큼 반복, n2를 지정하지 않으면 `n1` 이상만 반복 |\n",
    "| `\\[ abc \\]` | 안에 문자들 중 한 개의 문자와 매치, a-z처럼 범위도 지정 가능 |\n",
    "| `\\[ ^a \\]` | 해당 문자를 제외하고 매치 |\n",
    "| `a\\|b` | `a` 또는 `b`를 나타냄 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGv0DLZu1PqE"
   },
   "source": [
    "* 정규 표현식에 자주 사용하는 역슬래시(\\\\)를 이용한 문자 규칙\n",
    "\n",
    "| 문자 | 설명 |\n",
    "| - | - |\n",
    "| `\\\\` | 역슬래시 자체를 의미 |\n",
    "| `\\d` | 모든 숫자를 의미, [0-9]와 동일 |\n",
    "| `\\D` | 숫자를 제외한 모든 문자를 의미, [^0-9]와 동일 |\n",
    "| `\\s` | 공백을 의미, [ \\t\\n\\r\\f\\v]와 동일|\n",
    "| `\\S` | 공백을 제외한 모든 문자를 의미, [^ \\t\\n\\r\\f\\v]와 동일 |\n",
    "| `\\w` | 문자와 숫자를 의미, [a-zA-Z0-9]와 동일 |\n",
    "| `\\W` | 문자와 숫자를 제외한 다른 문자를 의미, [^a-zA-Z0-9]와 동일 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEIH8rWo1bJf"
   },
   "source": [
    "#### match\n",
    "\n",
    "* 컴파일한 정규 표현식을 이용해 문자열이 정규 표현식과 맞는지 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:30:12.275324Z",
     "start_time": "2021-09-09T00:30:12.271321Z"
    },
    "id": "V8UD0NCw8UVm"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:31:34.336767Z",
     "start_time": "2021-09-09T00:31:34.333765Z"
    },
    "id": "lxzhmTi11wS1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='abc'>\n",
      "<re.Match object; span=(0, 3), match='abc'>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "check = 'ab.'\n",
    "\n",
    "print(re.match(check, 'abc'))\n",
    "print(re.match(check, 'abcd'))\n",
    "\n",
    "print(re.match(check, 'c'))\n",
    "print(re.match(check, 'ab'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lICVJ-q_1c_M"
   },
   "source": [
    "#### compile\n",
    "\n",
    "* compile을 사용하면 여러 번 사용할 경우 일반 사용보다 더 빠른 속도를 보임\n",
    "* compile을 통해 정규 표현식을 사용할 경우 `re`가 아닌 컴파일한 객체 이름을 통해 사용해야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:37:17.252111Z",
     "start_time": "2021-09-09T00:37:16.533102Z"
    },
    "id": "jDTSl5S31wms"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반 사용시 소요 시간 0.5177593231201172\n",
      "일반 사용시 소요 시간 0.18824076652526855\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "normal_s_time = time.time()\n",
    "check = 'ab.'\n",
    "for i in range(1000000):\n",
    "    re.match(check,'abc')\n",
    "print('일반 사용시 소요 시간', time.time() - normal_s_time)\n",
    "\n",
    "compile_s_time = time.time()\n",
    "r_c = re.compile('ab.')\n",
    "for i in range(1000000):\n",
    "    r_c.match('abc')\n",
    "print('일반 사용시 소요 시간', time.time() - compile_s_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6OcEzN81fNV"
   },
   "source": [
    "#### search\n",
    "\n",
    "* match와 다르게, search는 문자열의 전체를 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:41:25.956477Z",
     "start_time": "2021-09-09T00:41:25.951471Z"
    },
    "id": "Mg1iU0Kg1w70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 1), match='a'>\n",
      "<re.Match object; span=(0, 1), match='a'>\n",
      "None\n",
      "<re.Match object; span=(3, 5), match='ab'>\n",
      "<re.Match object; span=(0, 2), match='ab'>\n"
     ]
    }
   ],
   "source": [
    "check = 'ab?'\n",
    "\n",
    "print(re.match(check, 'a'))\n",
    "print(re.search(check, 'a'))\n",
    "print(re.match(check, 'kkkab'))\n",
    "print(re.search(check,'kkkab'))\n",
    "print(re.match(check,'ab'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmkvc1741g5P"
   },
   "source": [
    "#### split\n",
    "\n",
    "* 정규표현식에 해당하는 문자열을 기준으로 문자열을 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:43:56.792522Z",
     "start_time": "2021-09-09T00:43:56.783514Z"
    },
    "id": "6bLf5Hgs1xZk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abbc', 'abcbab']\n",
      "['ab', ' abb', ' ab', 'bab']\n",
      "['s', 'abc ', 'v', '', 's ', 'sss ga', 'a']\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(' ')\n",
    "print(r.split('abc abbc abcbab'))\n",
    "\n",
    "r = re.compile('c')\n",
    "print(r.split('abc abbc abcbab'))\n",
    "\n",
    "r = re.compile('[1-9]')\n",
    "print(r.split('s1abc 2v23s 4sss ga3a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTor-yg_1h49"
   },
   "source": [
    "#### sub\n",
    "\n",
    "* 정규 표현식과 일치하는 부분을 다른 문자열로 교체\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:47:30.506817Z",
     "start_time": "2021-09-09T00:47:30.493924Z"
    },
    "id": "ZlqOk9DY1xtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "abc defg\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('[a-z]', 'abcdefg', '1'))\n",
    "\n",
    "print(re.sub('[^a-z]', 'abc defg', '1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUzY6Vz31i8U"
   },
   "source": [
    "#### findall\n",
    "\n",
    "* 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 리스트로 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:49:33.715088Z",
     "start_time": "2021-09-09T00:49:33.699076Z"
    },
    "id": "Osi3UYYv1yHP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4']\n",
      "['!', '!', '#', '$', '$', '#', '@']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall('[\\d]', '1ab 2cd 3ef d4d'))# 숫자만\n",
    "\n",
    "print(re.findall('[\\W]', '!abcd!#$$#@12'))# 문자 숫자가 아닌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxLLmwJu1kTt"
   },
   "source": [
    "#### finditer\n",
    "\n",
    "* 컴파일한 정규 표현식을 이용해 정규 표현식과 맞는 모든 문자(열)을 `iterator` 객체로 반환\n",
    "* `iterator` 객체를 이용하면 생성된 객체를 하나씩 자동으로 가져올 수 있어 처리가 간편함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:52:07.436982Z",
     "start_time": "2021-09-09T00:52:07.428975Z"
    },
    "id": "6NOFG3Hy1ycd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x0000024833D180A0>\n",
      "<re.Match object; span=(0, 1), match='1'>\n",
      "<re.Match object; span=(4, 5), match='2'>\n",
      "<re.Match object; span=(8, 9), match='3'>\n",
      "<re.Match object; span=(13, 14), match='4'>\n"
     ]
    }
   ],
   "source": [
    "iter1 = re.finditer('[\\d]', '1ab 2cd 3ef d4d')\n",
    "print(iter1)\n",
    "for i in iter1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:52:17.860551Z",
     "start_time": "2021-09-09T00:52:17.852028Z"
    },
    "id": "6NOFG3Hy1ycd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<callable_iterator object at 0x0000024833B3BC70>\n",
      "<re.Match object; span=(0, 1), match='!'>\n",
      "<re.Match object; span=(5, 6), match='!'>\n",
      "<re.Match object; span=(6, 7), match='#'>\n",
      "<re.Match object; span=(7, 8), match='$'>\n",
      "<re.Match object; span=(8, 9), match='@'>\n"
     ]
    }
   ],
   "source": [
    "iter2 = re.finditer('[\\W]', '!abcd!#$@12')\n",
    "print(iter2)\n",
    "for i in iter2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn4C67oivxxN"
   },
   "source": [
    "### 토큰화(Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqPZHQZPzFvc"
   },
   "source": [
    "* 특수문자에 대한 처리\n",
    "\n",
    "  + 단어에 일반적으로 사용되는 알파벳, 숫자와는 다르게 특수문자는 별도의 처리가 필요            \n",
    "  + 일괄적으로 단어의 특수문자를 제거하는 방법도 있지만 특수문자가 단어에 특별한 의미를 가질 때 이를 학습에 반영시키지 못할 수도 있음\n",
    "  + 특수문자에 대한 일괄적인 제거보다는 데이터의 특성을 파악하고, 처리를 하는 것이 중요\n",
    "       * 예를 들어 !는 강조, ? 질문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrZTwnlTyzYV"
   },
   "source": [
    "* 특정 단어에 대한 토큰 분리 방법\n",
    "\n",
    "  + 한 단어지만 토큰으로 분리할 때 판단되는 문자들로 이루어진 *we're*, *United Kingdom* 등의 단어는 어떻게 분리해야 할지 선택이 필요   \n",
    "  + we're은 한 단어이나 분리해도 단어의 의미에 별 영향을 끼치진 않지만 *United Kingdom*은 두 단어가 모여 특정 의미를 가리켜 분리해선 안됨\n",
    "  + 사용자가 단어의 특성을 고려해 토큰을 분리하는 것이 학습에 유리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9_k9rA6v0KM"
   },
   "source": [
    "#### 단어 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t02uSgcSv6IQ"
   },
   "source": [
    "* 파이썬 내장 함수인 `split`을 활용해 단어 토큰화\n",
    "* 공백을 기준으로 단어를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:54:54.466006Z",
     "start_time": "2021-09-09T00:54:54.448992Z"
    },
    "id": "bV6CNv1Sv62F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time', 'is', 'gold']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Time is gold'\n",
    "tokens = [x for x in sentence.split(' ')]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_PDCM7YwEi9"
   },
   "source": [
    "* 토큰화는 `nltk` 패키지의 `tokenize` 모듈을 사용해 손쉽게 구현 가능\n",
    "* 단어 토큰화는 `word_tokenize()` 함수를 사용해 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:55:50.894698Z",
     "start_time": "2021-09-09T00:55:49.795988Z"
    },
    "id": "isgXAhV7wEo7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:56:27.384659Z",
     "start_time": "2021-09-09T00:56:27.372650Z"
    },
    "id": "vXkXYwoywHAl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time', 'is', 'gold']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcmIjFyRwJpW"
   },
   "source": [
    "#### 문장 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Jkvs6Jov7QF"
   },
   "source": [
    "* 문장 토큰화는 줄바꿈 문자('\\n')를 기준으로 문장을 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:58:56.960673Z",
     "start_time": "2021-09-09T00:58:56.943657Z"
    },
    "id": "MkJ60tlTv7Ux"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world is a beautiful book.\n",
      "But of little use to him who cannot read it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The world is a beautiful book.',\n",
       " 'But of little use to him who cannot read it.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = 'The world is a beautiful book.\\nBut of little use to him who cannot read it.'\n",
    "print(sentences)\n",
    "\n",
    "tokens = [x for x in sentences.split('\\n')]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDSxHUHTwVzG"
   },
   "source": [
    "* 문장 토큰화는 `sent_tokenize()` 함수를 사용해 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T00:58:57.668617Z",
     "start_time": "2021-09-09T00:58:57.656069Z"
    },
    "id": "0oR8iHWiwV6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The world is a beautiful book.',\n",
       " 'But of little use to him who cannot read it.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "tokens = sent_tokenize(sentences)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ca3lOErwbGN"
   },
   "source": [
    "* 문장 토큰화에서는 온점(.)의 처리를 위해 이진 분류기를 사용할 수도 있음\n",
    "* 온점은 문장과 문장을 구분해줄 수도, 문장에 포함된 단어를 구성할 수도 있기 때문에 이를 이진 분류기로 분류해 더욱 좋은 토큰화를 구현할 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVPmqCnV2Ydt"
   },
   "source": [
    "#### 정규 표현식을 이용한 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hkxXlZb2j0O"
   },
   "source": [
    "* 토큰화 기능을 직접 구현할 수도 있지만 정규 표현식을 이용해 간단하게 구현할 수도 있음\n",
    "* `nltk` 패키지는 정규 표현식을 사용하는 토큰화 도구인 `RegexpTokenizer`를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T01:01:47.221141Z",
     "start_time": "2021-09-09T01:01:47.208412Z"
    },
    "id": "9KOEXR7R2cyV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where there's a will, there's a way\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Where', 'there', 's', 'a', 'will', 'there', 's', 'a', 'way']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sentence = 'Where there\\'s a will, there\\'s a way'\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "tokenizer = RegexpTokenizer('[\\w]+') # 문자 숫자 1글자 이상\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T01:02:49.036242Z",
     "start_time": "2021-09-09T01:02:49.022230Z"
    },
    "id": "Lhdy85nr2fTt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Where', \"there's\", 'a', 'will,', \"there's\", 'a', 'way']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('[\\s]+', gaps=True) # \n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMmCGvTFirsi"
   },
   "source": [
    "#### 케라스를 이용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:14:58.572196Z",
     "start_time": "2021-09-09T02:14:58.559159Z"
    },
    "id": "pghLPLfSirOJ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-c613a4edc014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Where there\\'s a will, there\\'s a way'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence = 'Where there\\'s a will, there\\'s a way'\n",
    "\n",
    "text_to_word_sequence(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOZj2hkzi9Ki"
   },
   "source": [
    "#### TextBlob을 이용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:15:05.371128Z",
     "start_time": "2021-09-09T02:15:05.352575Z"
    },
    "id": "oIDyF_gLi84n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Where', 'there', \"'s\", 'a', 'will', 'there', \"'s\", 'a', 'way'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentence = 'Where there\\'s a will, there\\'s a way'\n",
    "\n",
    "blob = TextBlob(sentence)\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5Vvqfynlf9Z"
   },
   "source": [
    "#### 기타 토크나이저\n",
    "\n",
    "* WhiteSpaceTokenizer: 공백을 기준으로 토큰화\n",
    "* WordPunktTokenizer: 텍스트를 알파벳 문자, 숫자, 알파벳 이외의 문자 리스트로 토큰화\n",
    "* MWETokenizer: MWE는 Multi-Word Expression의 약자로 'republic of korea'와 같이 여러 단어로 이뤄진 특정 그룹을 한 개체로 취급\n",
    "* TweetTokenizer: 트위터에서 사용되는 문장의 토큰화를 위해서 만들어졌으며, 문장 속 감성의 표현과 감정을 다룸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQh3deRog1It"
   },
   "source": [
    "### n-gram 추출\n",
    "\n",
    "* n-gram은 n개의 어절이나 음절을 연쇄적으로 분류해 그 빈도를 분석\n",
    "* n=1일 때는 unigram, n=2일 때는 bigram, n=3일 때는 trigram으로 불림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:07:28.826504Z",
     "start_time": "2021-09-09T02:07:28.818498Z"
    },
    "id": "2Jj0RiGng7bV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('There', 'is'),\n",
       " ('is', 'no'),\n",
       " ('no', 'royal'),\n",
       " ('royal', 'road'),\n",
       " ('road', 'to'),\n",
       " ('to', 'learning')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "sentence = 'There is no royal road to learning'\n",
    "\n",
    "bigram = list(ngrams(sentence.split(), 2))\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:07:53.182828Z",
     "start_time": "2021-09-09T02:07:53.177823Z"
    },
    "id": "-sEZ6IfGh2q2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('There', 'is', 'no'),\n",
       " ('is', 'no', 'royal'),\n",
       " ('no', 'royal', 'road'),\n",
       " ('royal', 'road', 'to'),\n",
       " ('road', 'to', 'learning')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = list(ngrams(sentence.split(), 3))\n",
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:09:41.783332Z",
     "start_time": "2021-09-09T02:09:41.745301Z"
    },
    "id": "0g1yxT62iMvA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['There', 'is']),\n",
       " WordList(['is', 'no']),\n",
       " WordList(['no', 'royal']),\n",
       " WordList(['royal', 'road']),\n",
       " WordList(['road', 'to']),\n",
       " WordList(['to', 'learning'])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(sentence)\n",
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:09:45.721343Z",
     "start_time": "2021-09-09T02:09:45.710333Z"
    },
    "id": "2hkjduP0idli"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['There', 'is', 'no']),\n",
       " WordList(['is', 'no', 'royal']),\n",
       " WordList(['no', 'royal', 'road']),\n",
       " WordList(['royal', 'road', 'to']),\n",
       " WordList(['road', 'to', 'learning'])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iRYvPrOZbGQ"
   },
   "source": [
    "### PoS(Parts of Speech) 태깅 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xRajzx4_5ng"
   },
   "source": [
    "* PoS는 품사를 의미하며, PoS 태깅은 문장 내에서 단어에 해당하는 각 품사를 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:16:41.446246Z",
     "start_time": "2021-09-09T02:16:41.233713Z"
    },
    "id": "Vo4n1kbt_4Pt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:17:09.808206Z",
     "start_time": "2021-09-09T02:17:09.800199Z"
    },
    "id": "OcVS13f8ATMT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Think',\n",
       " 'like',\n",
       " 'man',\n",
       " 'of',\n",
       " 'action',\n",
       " 'and',\n",
       " 'act',\n",
       " 'like',\n",
       " 'man',\n",
       " 'of',\n",
       " 'thought',\n",
       " '.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(\"Think like man of action and act like man of thought.\")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:17:46.105346Z",
     "start_time": "2021-09-09T02:17:45.312761Z"
    },
    "id": "YvoGzfP2AjqJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Think', 'VBP'),\n",
       " ('like', 'IN'),\n",
       " ('man', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('action', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('act', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('man', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('thought', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:18:56.244583Z",
     "start_time": "2021-09-09T02:18:56.238578Z"
    },
    "id": "5AaI3nFwB_qL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('rolling', 'VBG'),\n",
       " ('stone', 'NN'),\n",
       " ('gathers', 'NNS'),\n",
       " ('no', 'DT'),\n",
       " ('moss', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(\"A rolling stone gathers no moss.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWUanibELmmi"
   },
   "source": [
    "* PoS 태그 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RGD-0sVAwaV"
   },
   "source": [
    "| Number | Tag | Description | 설명 |\n",
    "| -- | -- | -- | -- |\n",
    "| 1 | `CC` | Coordinating conjunction |\n",
    "| 2 | `CD` | Cardinal number |\n",
    "| 3 | `DT` | Determiner | 한정사\n",
    "| 4 | `EX` | Existential there |\n",
    "| 5 | `FW` | Foreign word | 외래어 |\n",
    "| 6 | `IN` | Preposition or subordinating conjunction | 전치사 또는 종속 접속사 |\n",
    "| 7 | `JJ` | Adjective | 형용사 |\n",
    "| 8 | `JJR` | Adjective, comparative | 헝용사, 비교급 |\n",
    "| 9 | `JJS` | Adjective, superlative | 형용사, 최상급 |\n",
    "| 10 | `LS` | List item marker |\n",
    "| 11 | `MD` | Modal |\n",
    "| 12 | `NN` | Noun, singular or mass | 명사, 단수형 |\n",
    "| 13 | `NNS` | Noun, plural | 명사, 복수형 |\n",
    "| 14 | `NNP` | Proper noun, singular | 고유명사, 단수형 |\n",
    "| 15 | `NNPS` | Proper noun, plural | 고유명사, 복수형 |\n",
    "| 16 | `PDT` | Predeterminer | 전치한정사 |\n",
    "| 17 | `POS` | Possessive ending | 소유형용사 |\n",
    "| 18 | `PRP` | Personal pronoun | 인칭 대명사 |\n",
    "| 19 | `PRP$` | Possessive pronoun | 소유 대명사 |\n",
    "| 20 | `RB` | Adverb | 부사 |\n",
    "| 21 | `RBR` | Adverb, comparative | 부사, 비교급 |\n",
    "| 22 | `RBS` | Adverb, superlative | 부사, 최상급 |\n",
    "| 23 | `RP` | Particle |\n",
    "| 24 | `SYM` | Symbol | 기호\n",
    "| 25 | `TO` | to |\n",
    "| 26 | `UH` | Interjection | 감탄사 |\n",
    "| 27 | `VB` | Verb, base form | 동사, 원형 |\n",
    "| 28 | `VBD` | Verb, past tense | 동사, 과거형 |\n",
    "| 29 | `VBG` | Verb, gerund or present participle | 동사, 현재분사 |\n",
    "| 30 | `VBN` | Verb, past participle | 동사, 과거분사 |\n",
    "| 31 | `VBP` | Verb, non-3rd person singular present | 동사, 비3인칭 단수 |\n",
    "| 32 | `VBZ` | Verb, 3rd person singular present | 동사, 3인칭 단수 |\n",
    "| 33 | `WDT` | Wh-determiner |\n",
    "| 34 | `WP` | Wh-pronoun |\n",
    "| 35 | `WP$` | Possessive wh-pronoun |\n",
    "| 36 | `WRB` | Wh-adverb |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmDuyhjxugFN"
   },
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj2rvWzwuy7o"
   },
   "source": [
    "* 영어의 전치사(on, in), 한국어의 조사(을, 를) 등은 분석에 필요하지 않은 경우가 많음\n",
    "* 길이가 짧은 단어, 등장 빈도 수가 적은 단어들도 분석에 큰 영향을 주지 않음\n",
    "* 일반적으로 사용되는 도구들은 해당 단어들을 제거해주지만 완벽하게 제거되지는 않음\n",
    "* 사용자가 불용어 사전을 만들어 해당 단어들을 제거하는 것이 좋음\n",
    "* 도구들이 걸러주지 않는 전치사, 조사 등을 불용어 사전을 만들어 불필요한 단어들을 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:22:19.161236Z",
     "start_time": "2021-09-09T02:22:19.147222Z"
    },
    "id": "hjFp9u9quy_t"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['on', 'in', 'the']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = 'on in the'\n",
    "stop_words = stop_words.split()\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:23:35.696407Z",
     "start_time": "2021-09-09T02:23:35.690401Z"
    },
    "id": "9nKwwtR6uzCr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['singer', 'stage']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'singer on the stage'\n",
    "sentence = sentence.split(' ')\n",
    "nouns = []\n",
    "for noun in sentence:\n",
    "    if noun not in stop_words:\n",
    "        nouns.append(noun)\n",
    "\n",
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykTS2yeMMEXF"
   },
   "source": [
    "* `nltk` 패키지에 불용어 리스트 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:24:19.952448Z",
     "start_time": "2021-09-09T02:24:19.786689Z"
    },
    "id": "XlDpO3e-MHwa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:25:05.620394Z",
     "start_time": "2021-09-09T02:25:05.612388Z"
    },
    "id": "1jC408N2MRR0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:25:43.462363Z",
     "start_time": "2021-09-09T02:25:43.451355Z"
    },
    "id": "zShCTozjMYWG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'you', 'do', 'not', 'walk', 'today', ',', 'you', 'will', 'have', 'to', 'run', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "s = 'If you do not walk today, you will have to run tomorrow.'\n",
    "words = word_tokenize(s)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:26:14.654896Z",
     "start_time": "2021-09-09T02:26:14.644305Z"
    },
    "id": "qd_gC78EOPdv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If', 'walk', 'today', ',', 'run', 'tomorrow', '.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stopwords = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        no_stopwords.append(w)\n",
    "no_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXO6E3E--gQy"
   },
   "source": [
    "### 철자 교정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AM6lTU2w-q7A"
   },
   "source": [
    "* 텍스트에 오탈자가 존재하는 경우가 있음\n",
    "* 예를 들어, 단어 'apple'을 'aplpe'과 같이 철자 순서가 바뀌거나 spple 같이 철자가 틀릴 수 있음\n",
    "* 사람이 적절한 추정을 통해 이해하는데는 문제가 없지만, 컴퓨터는 이러한 단어를 그대로 받아들여 처리가 필요\n",
    "* 철자 교정 알고리즘은 이미 개발되어 워드 프로세서나 다양한 서비스에서 많이 적용됨\n",
    "됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:28:04.437683Z",
     "start_time": "2021-09-09T02:27:59.128342Z"
    },
    "id": "m3hUcYaYRwVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.5.0.tar.gz (622 kB)\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py): started\n",
      "  Building wheel for autocorrect (setup.py): finished with status 'done'\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.5.0-py3-none-any.whl size=621854 sha256=723bc93c5b9a7ee7aa0eb6a4e96afb0d84892e62c2695d4d7eb695589d5f7e4c\n",
      "  Stored in directory: c:\\users\\bigne\\appdata\\local\\pip\\cache\\wheels\\da\\03\\6e\\62a48359ab630e39939dbb392cc079923bb77664e97a47645d\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bigne\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# !pip install autocorrect\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:29:36.736967Z",
     "start_time": "2021-09-09T02:29:36.682913Z"
    },
    "id": "4H4TaYE7REcI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people\n",
      "people\n",
      "people\n"
     ]
    }
   ],
   "source": [
    "spell = Speller('en') # 영어로 설정\n",
    "\n",
    "print(spell('peoplle'))\n",
    "print(spell('peope'))\n",
    "print(spell('peopae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:31:28.820393Z",
     "start_time": "2021-09-09T02:31:28.810382Z"
    },
    "id": "VO03TM_KSL4V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Early', 'biird', 'catchess', 'the', 'womm']\n"
     ]
    }
   ],
   "source": [
    "s = word_tokenize(\"Early biird catchess the womm\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:31:29.015761Z",
     "start_time": "2021-09-09T02:31:29.000747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early bird catches the worm\n"
     ]
    }
   ],
   "source": [
    "ss = ' '.join([spell(s) for s in s])\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4_svyI2myE3"
   },
   "source": [
    "### 언어의 단수화와 복수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:32:33.020220Z",
     "start_time": "2021-09-09T02:32:33.017217Z"
    },
    "id": "3tDE8Aeumxml"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apples', 'bananas', 'oranges']\n",
      "['apple', 'banana', 'orange']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "words = 'apples bananas oranges'\n",
    "tb = TextBlob(words)\n",
    "\n",
    "print(tb.words)\n",
    "print(tb.words.singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:33:12.586773Z",
     "start_time": "2021-09-09T02:33:12.568759Z"
    },
    "id": "WLqLAg6Snfi8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'train', 'airplane']\n",
      "['cars', 'trains', 'airplanes']\n"
     ]
    }
   ],
   "source": [
    "words = 'car train airplane'\n",
    "\n",
    "tb = TextBlob(words)\n",
    "\n",
    "print(tb.words)\n",
    "print(tb.words.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-9i7ubNX0mD"
   },
   "source": [
    "### 어간(Stemming) 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:33:31.932900Z",
     "start_time": "2021-09-09T02:33:31.928895Z"
    },
    "id": "3_28SNykTEbf"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:33:40.818110Z",
     "start_time": "2021-09-09T02:33:40.811105Z"
    },
    "id": "LCwnOPFNTP2v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'applic'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('application')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:35:45.771955Z",
     "start_time": "2021-09-09T02:35:45.767952Z"
    },
    "id": "O6O5VoWcTQuO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'begin'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('beginning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:36:06.823003Z",
     "start_time": "2021-09-09T02:36:06.816997Z"
    },
    "id": "O6O5VoWcTQuO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catch'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('catches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:36:06.823003Z",
     "start_time": "2021-09-09T02:36:06.816997Z"
    },
    "id": "O6O5VoWcTQuO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'educ'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-zauW83XwJ8"
   },
   "source": [
    "### 표제어(Lemmatization) 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:36:53.357083Z",
     "start_time": "2021-09-09T02:36:52.664590Z"
    },
    "id": "FTHh2W06TlPm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:37:05.061027Z",
     "start_time": "2021-09-09T02:37:03.980983Z"
    },
    "id": "LF_jyPwaTzV5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('application')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:37:31.915949Z",
     "start_time": "2021-09-09T02:37:31.906931Z"
    },
    "id": "WrFilM4jWF9p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beginning'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('beginning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:37:44.372011Z",
     "start_time": "2021-09-09T02:37:44.364003Z"
    },
    "id": "T1pwiZSgWV8Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'catch'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('catches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:37:53.703392Z",
     "start_time": "2021-09-09T02:37:53.700390Z"
    },
    "id": "MoKJNaJ8WT2x"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YauGaSZHWg3R"
   },
   "source": [
    "### 개체명 인식(Named Entity Recognition)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:39:08.201885Z",
     "start_time": "2021-09-09T02:39:06.790350Z"
    },
    "id": "t5tcQw9FW8fi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\bigne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:39:20.309257Z",
     "start_time": "2021-09-09T02:39:20.295532Z"
    },
    "id": "WqWjHuthXWp4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rome was not bulit in a day\n"
     ]
    }
   ],
   "source": [
    "s = 'Rome was not bulit in a day'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:39:39.215964Z",
     "start_time": "2021-09-09T02:39:39.209960Z"
    },
    "id": "NnnBqd-YXkwa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rome', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('bulit', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('day', 'NN')]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = nltk.pos_tag(word_tokenize(s))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:40:03.797113Z",
     "start_time": "2021-09-09T02:40:03.779097Z"
    },
    "id": "kjnWKrpPYWax"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NE Rome/NNP) was/VBD not/RB bulit/VBN in/IN a/DT day/NN)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.ne_chunk(tags, binary=True)\n",
    "print(entities) # NE : Named Entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOVaBRHZauv8"
   },
   "source": [
    "### 단어 중의성(Lexical Ambiguity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-09T02:43:06.465992Z",
     "start_time": "2021-09-09T02:43:06.458986Z"
    },
    "id": "j9Y7u8Kqawho"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'saw', 'bats', '.']\n",
      "Synset('saw.v.01')\n",
      "Synset('squash_racket.n.01')\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.wsd import lesk\n",
    "\n",
    "s = 'I saw bats.'\n",
    "\n",
    "print(word_tokenize(s))\n",
    "print(lesk(word_tokenize(s), 'saw'))\n",
    "print(lesk(word_tokenize(s), 'bats'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FU4T_80TuSdp"
   },
   "source": [
    "## 한국어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qeUwjUq3lkH"
   },
   "source": [
    "### 정규표현식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HSV73e530v8"
   },
   "source": [
    "* 한국어 정규 표현식도 대부분의 문법은 영어 정규 표현식과 같음\n",
    "* 한국어는 자음과 모음이 분리되어 있기 때문에, 문법을 지정할 때는 자음과 모음을 동시에 고려해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKYR7b3U44RM"
   },
   "source": [
    "#### match\n",
    "\n",
    "* 컴파일한 정규 표현식을 이용해 문자열이 정규 표현식과 맞는지 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgwMiWUe4zJN"
   },
   "outputs": [],
   "source": [
    "1: 15:43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVxRcA8Z457T"
   },
   "source": [
    "#### search\n",
    "\n",
    "* match와 다르게, search는 문자열의 전체를 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWS4rgxq48N7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCWlVO4S48Ts"
   },
   "source": [
    "#### sub\n",
    "\n",
    "* 정규 표현식과 일치하는 부분을 다른 문자열로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Kv_oNRs48fU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pe_7bBBdvlXQ"
   },
   "source": [
    "### 토큰화(Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aEfI5YHysxv"
   },
   "source": [
    "* 한국어를 학습 데이터를 사용할 때는 언어의 특성으로 인해 추가로 고려해야 할 사항이 존재\n",
    "* 한국어는 띄어쓰기를 준수하지 않아도 의미가 전달되는 경우가 많아 띄어쓰기가 지켜지지 않을 가능성이 존재\n",
    "* 띄어쓰기가 지켜지지 않으면 정상적인 토큰 분리가 이루어지지 않음\n",
    "* 한국어는 형태소라는 개념이 존재해 추가로 고려해주어야만 함\n",
    "* '그는', '그가' 등의 단어들은 같은 의미를 가리키지만 텍스트 처리에서는 다르게 받아들일 수 있어 처리를 해줘야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "765_lRMqwlZg"
   },
   "source": [
    "#### 한국어 자연어 처리 konlpy와 형태소 분석기 MeCab 설치\n",
    "\n",
    "* https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CoLF80pwnc9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJhzBOckvqr9"
   },
   "source": [
    "#### 단어 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-34oqwZwsC3"
   },
   "source": [
    "* 한국어는 공백으로 단어를 분리해도 조사, 접속사 등이 남아 분석에 어려움이 있음\n",
    "* 이를 해결해주는 한국어 토큰화는 조사, 접속사를 분리해주거나 제거\n",
    "* 한국어 토큰화를 사용하기 위해선 `konlpy`와 `mecab`이라는 라이브러리가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8m9Inqu0wrd5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwoU6RioB14R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKg9p-SlwyRe"
   },
   "source": [
    "* 토큰화만 실행할 때는 `tagger.morphs()`라는 함수를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ist7zW_RwvcO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7u6-78hw0gD"
   },
   "source": [
    "* 형태소만 사용하고 싶을 때는 `tagger.nouns()`라는 함수를 이용해 조사, 접속사 등을 제거 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1D_Bg0gewwm9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThPaMDOGvsiW"
   },
   "source": [
    "#### 문장 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okKRCWhdxMbH"
   },
   "source": [
    "* 한국어 문장을 토큰화할 때는 kss(korean sentence splitter) 라이브러리 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOKstGpcxv5-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1VGyGg5yN-d"
   },
   "source": [
    "* 라이브러리를 이용해도 한국어에는 전치 표현이 존재해 제대로 토큰화가 안됨\n",
    "* 좀 더 나은 학습을 위해 사용자는 해당 부분을 따로 처리해주어야만 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIlTDBv7xMg7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAq7fR4r7cpA"
   },
   "source": [
    "#### 정규 표현식을 이용한 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkCInLL67l9M"
   },
   "source": [
    "* 한국어도 정규 표현식을 이용해 토큰화 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lyscjy5a7c4r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmXhfXCC7c0u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZdfxeFsn25k"
   },
   "source": [
    "#### 케라스를 이용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_Zn15pNn25o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzEFiZt7n25z"
   },
   "source": [
    "#### TextBlob을 이용한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgzHxLPyn252"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xaQF79AaKiN"
   },
   "source": [
    "## Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-FpBEoS3CBY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VIjY4WXr48FE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMeaVigC4eE6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2ud_G3LqIpw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n2gkHk17NyC"
   },
   "source": [
    "## 문서 단어 행렬(DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F87rTUZs7S2p"
   },
   "source": [
    "* 문서 단어 행렬(Document-Term Matrix)은 문서에 등장하는 여러 단어들의 빈도를 행렬로 표현\n",
    "* 각 문서에 대한 BoW를 하나의 행렬로 표현한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4pNYz6V7SO9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z-bPw94FTGb"
   },
   "source": [
    "## 어휘 빈도-문서 역빈도(TF-IDF) 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-0f-hz5Fgai"
   },
   "source": [
    "* 어휘 빈도-문서 역빈도(TF-IDF; Term Frequency-Inverse Docunment Frequency)는 단순히 빈도수가 높은 단어가 핵심어가 아닌, 특정 문서에서만 집중적으로 등장할 때 해당 단어가 문서의 주제를 잘 담고 있는 핵심어라고 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3kEwiZBJSSB"
   },
   "source": [
    "* 특정 문서에서 특정단어가 많이 등장하고 그 단어가 다른 문서에서 적게 등장할 때, 그 단어를 특정 문서의 핵심어로 간주\n",
    "* 어휘 빈도-문서 역빈도는 어휘 빈도와 역문서 빈도를 곱해 계산 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7wTnMY8JEDC"
   },
   "source": [
    "* **어휘 빈도**는 특정 문서에서 특정 단어가 많이 등장하는 것을 의미\n",
    "\n",
    "$$ tf_{x,y} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8289-mSJF1p"
   },
   "source": [
    "* **역문서 빈도**는 다른 문서에서 등장하지 않는 단어 빈도를 의미\n",
    "\n",
    "$$ log(N/df_x) $$      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MyZYLgRJH8R"
   },
   "source": [
    "* **어휘 빈도-문서 역빈도**는 다음과 같이 표현\n",
    "\n",
    "$$ W_{x,y} = tf_{x,y} * log(N/df_x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv_23ugcKMjS"
   },
   "source": [
    "* tf-idf를 편리하게 계산하기 위해 `scikit-learn`의 `tfidfvectorizer`를 이용\n",
    "* 앞서 계산한 단어 빈도 수를 입력하여 tf-idf로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JH25kuy-J8cj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoGurU81KqYD"
   },
   "source": [
    "* 좀 더 편리하게 확인하기 위해 데이터프레임으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSjYYeDBKGEr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_1 자연어 처리(Natural Language Processing).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "653.993px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
